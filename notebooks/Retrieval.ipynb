{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Retrieval Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uqqq rich openai tiktoken wandb langchain unstructured tabulate pdf2image chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from getpass import getpass\n",
    "from rich.markdown import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any([\"VSCODE\" in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window.')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain\n",
    "LangChain is a framework for developing applications powered by language models. We will use some of its features in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need a single line of code to start tracing Langchain with W&B\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "\n",
    "# configuring the wandb project name\n",
    "os.environ[\"WANDB_PROJECT\"] = \"llmapps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing documents\n",
    "We will use a sample of markdown documents in this notebook. Let's find them and make sure we can stuff them into the prompt. That means they may need to be chunked and not exceed some number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"text-davinci-003\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ghost\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ghost\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "def find_md_files(directory):\n",
    "  \"Find all markdown files in a directory and return a LangChain Document\"\n",
    "  dl = DirectoryLoader(directory, \"**/*.md\")\n",
    "  return dl.load()\n",
    "\n",
    "documents = find_md_files(\"../docs_sample/\")\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to count tokens in the documents, and for that we need the tokenizer\n",
    "tokenizer = tiktoken.encoding_for_model(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[310, 2135, 2330, 2592, 665, 1154, 387, 763, 2047, 2616, 1199]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to count the number of tokens in each document\n",
    "def count_tokens(documents):\n",
    "  token_counts = [len(tokenizer.encode(document.page_content)) for document in documents]\n",
    "  return token_counts\n",
    "\n",
    "count_tokens(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use LangChain built in MarkdownTextSplitter to split the documents into sections. Actually splitting Markdown without breaking syntax is not that easy. This splitter strips out syntax.\n",
    "\n",
    "- We can pass the `chunk_size` param and avoid lenghty chunks.\n",
    "- The `chunk_overlap` param is useful so you don't cut sentences randomly. This is less necessary with Markdown\n",
    "The MarkdownTextSplitter also takes care of removing double line breaks and save us some tokens that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 438)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "md_text_splitter = MarkdownTextSplitter(chunk_size=1000)\n",
    "document_sections = md_text_splitter.split_documents(documents)\n",
    "len(document_sections), max(count_tokens(document_sections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">description: Collaborate and share W&amp;B Reports with peers, co-workers, and your team.                              \n",
       "\n",
       "Collaborate on reports                                                                                             \n",
       "\n",
       "Once you have saved a report, you can select the Share button to collaborate. A draft copy of the report is created\n",
       "when you select the Edit button. Draft reports auto-save. Select Save to report to publish your changes to the     \n",
       "shared report.                                                                                                     \n",
       "\n",
       "A warning notification will appear if an edit conflict occurs. This can occur if you and another collaborator edit \n",
       "the same report at the same time. The warning notification will guide you to resolve potential edit conflicts.     \n",
       "\n",
       "Comment on reports                                                                                                 \n",
       "\n",
       "Click the comment button on a panel in a report to add a comment directly to that panel.                           \n",
       "\n",
       "Who can edit and share reports?                                                                                    \n",
       "\n",
       "Reports that are created within an individual's private project is only visible to that user. The user can share   \n",
       "their project to a team or to the public.                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "description: Collaborate and share W&B Reports with peers, co-workers, and your team.                              \n",
       "\n",
       "Collaborate on reports                                                                                             \n",
       "\n",
       "Once you have saved a report, you can select the Share button to collaborate. A draft copy of the report is created\n",
       "when you select the Edit button. Draft reports auto-save. Select Save to report to publish your changes to the     \n",
       "shared report.                                                                                                     \n",
       "\n",
       "A warning notification will appear if an edit conflict occurs. This can occur if you and another collaborator edit \n",
       "the same report at the same time. The warning notification will guide you to resolve potential edit conflicts.     \n",
       "\n",
       "Comment on reports                                                                                                 \n",
       "\n",
       "Click the comment button on a panel in a report to add a comment directly to that panel.                           \n",
       "\n",
       "Who can edit and share reports?                                                                                    \n",
       "\n",
       "Reports that are created within an individual's private project is only visible to that user. The user can share   \n",
       "their project to a team or to the public.                                                                          \n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(document_sections[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Let's now use embeddings with a vector database retriever to find relevant documents for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# We will use the OpenAIEmbeddings to embed the text, and  Chroma to store the vectors\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = Chroma.from_documents(document_sections, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a retriever from the db now, we can pass the `k` param to get the most relevant sections from the similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs=dict(k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Streaming LangChain activity to W&B at https://wandb.ai/arrogantemartin/llmapps/runs/h6o8klq3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: `WandbTracer` is currently in beta.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Please report any issues to https://github.com/wandb/wandb/issues with the tag `langchain`.\n"
     ]
    }
   ],
   "source": [
    "query = \"How can I share my W&B report with my team members in a public W&B project?\"\n",
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\docs_sample\\collaborate-on-reports.md\n",
      "..\\docs_sample\\collaborate-on-reports.md\n",
      "..\\docs_sample\\teams.md\n"
     ]
    }
   ],
   "source": [
    "# Let's see the results\n",
    "for doc in docs:\n",
    "  print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stuff Prompt\n",
    "We'll now take the content of the retrieved documents, stuff them into prompt templates along with the query and pass into an LLM to obtain the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "prompt = PROMPT.format(context=context, question=query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use langchain to call openai chat API with the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share a report in a public W&amp;B project, select the Share button on the upper right hand corner of the report.   \n",
       "You can either provide an email account or copy the magic link. Users invited by email will need to log into       \n",
       "Weights &amp; Biases to view the report. Users who are given a magic link do not need to log into Weights &amp; Biases to  \n",
       "view the report.                                                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "To share a report in a public W&B project, select the Share button on the upper right hand corner of the report.   \n",
       "You can either provide an email account or copy the magic link. Users invited by email will need to log into       \n",
       "Weights & Biases to view the report. Users who are given a magic link do not need to log into Weights & Biases to  \n",
       "view the report.                                                                                                   \n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI()\n",
    "response = llm.predict(prompt)\n",
    "Markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LangChain\n",
    "Langchain gives us tools to do this efficiently in few lines of code. Let's do the same using `RetrievalQA` chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">To share a report with your team members in a public W&amp;B project, select the Share button on the upper right hand  \n",
       "corner. You can either provide an email account or copy the magic link. Users invited by email will need to log    \n",
       "into Weights &amp; Biases to view the report. Users who are given a magic link to not need to log into Weights &amp; Biases\n",
       "to view the report. Shared reports are view-only.                                                                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "To share a report with your team members in a public W&B project, select the Share button on the upper right hand  \n",
       "corner. You can either provide an email account or copy the magic link. Users invited by email will need to log    \n",
       "into Weights & Biases to view the report. Users who are given a magic link to not need to log into Weights & Biases\n",
       "to view the report. Shared reports are view-only.                                                                  \n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
    "result = qa.run(query)\n",
    "\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privateGpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
