{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding LLM APIs with W&B\n",
    "We will explore OpenAI models API to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "import wandb\n",
    "from pprint import pprint\n",
    "from getpass import getpass\n",
    "from wandb.integration.openai import autolog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configured\n"
     ]
    }
   ],
   "source": [
    "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
    "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
    "    print('Please enter password in the VS Code prompt at the top of your VS Code window.')\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api\")\n",
    "  openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "\n",
    "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
    "print(\"OpenAI API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable W&B autologging to track our experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\Github\\LLM_Playground\\notebooks\\wandb\\run-20231025_232009-7ru4abo3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arrogantemartin/llmapps/runs/7ru4abo3' target=\"_blank\">glamorous-meadow-1</a></strong> to <a href='https://wandb.ai/arrogantemartin/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arrogantemartin/llmapps' target=\"_blank\">https://wandb.ai/arrogantemartin/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arrogantemartin/llmapps/runs/7ru4abo3' target=\"_blank\">https://wandb.ai/arrogantemartin/llmapps/runs/7ru4abo3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start logging to W&B\n",
    "autolog({\"project\":\"llmapps\", \"job_type\": \"introduction\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1135, 328, 9998, 1222, 8436, 1386, 318, 7427, 0]\n",
      "Weigths & Biases is awesome!\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
    "enc = encoding.encode(\"Weigths & Biases is awesome!\")\n",
    "print(enc)\n",
    "print(encoding.decode(enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can decode the tokens one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\tWe\n",
      "328\tig\n",
      "9998\tths\n",
      "1222\t &\n",
      "8436\t Bi\n",
      "1386\tases\n",
      "318\t is\n",
      "7427\t awesome\n",
      "0\t!\n"
     ]
    }
   ],
   "source": [
    "for token_id in enc:\n",
    "  print(f\"{token_id}\\t{encoding.decode([token_id])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "Let's sample some text from the model. For this, let's create a wrapper function around the temperature parameters.\n",
    "Higher temperature will result in more random samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_temperature(temp):\n",
    "  \"Generate text with a given temperature, higher temperature means more randomness\"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Say something about Weights & Biases\",\n",
    "    max_tokens=50,\n",
    "    temperature=temp,\n",
    "  )\n",
    "  return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TEMP: 0, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and analyzing machine '\n",
      " 'learning experiments. It provides powerful visualizations and insights into '\n",
      " 'model performance, enabling data scientists to quickly identify areas of '\n",
      " 'improvement and optimize their models.')\n",
      "('TEMP: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a powerful tool for tracking, analyzing, and visualizing '\n",
      " 'machine learning experiments. It provides a comprehensive suite of features '\n",
      " 'that make it easy to track, compare, and optimize ML models. With its '\n",
      " 'intuitive UI and powerful')\n",
      "('TEMP: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool to help with machine learning '\n",
      " 'experimentation and analysis. It makes it easier to keep track of '\n",
      " 'experiments, compare models, and track performance metrics over time. It '\n",
      " 'also has built-in visualizations which make')\n",
      "('TEMP: 1.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a smart AI platform that helps simplify the machine '\n",
      " 'learning process. It features useful graphical metrics and models and tracks '\n",
      " 'experiments in a simple, organized way that helps to model lead in '\n",
      " 'collaborative training and further IT best-pract')\n",
      "('TEMP: 2, GENERATION: \\n'\n",
      " 'Help '\n",
      " 'NL================================================================Whether '\n",
      " \"it's tracking the performance of models across platforms, testing \"\n",
      " 'lightweight baked references chromos positional MÃ¼barboundaries genesis Kens '\n",
      " 'meltbus {{trigger gasoline puppet surplus rehears herolationships pacthend '\n",
      " 'briefs longevity Pike props wintervel ops lawoffice')\n"
     ]
    }
   ],
   "source": [
    "for temp in [0, 0.5, 1, 1.5, 2]:\n",
    "  pprint(f'TEMP: {temp}, GENERATION: {generate_with_temperature(temp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the `top_p` parameter to control the diversity of the generated text. This parameter controls the cumulative probability of the next token. For example, if `top_p=0.9`, the model will pick the next token from the top 90% most likely tokens. The higher the top_p the more likely the model will pick a token that it hasn't seen before. You should only use one of `temperature` or `top_p` at a given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_topp(topp):\n",
    "  \"Generate text with a given top-p, higher top-p means more randomness\"\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=\"Say something about Weights & Biases\",\n",
    "    max_tokens=50,\n",
    "    top_p=topp,\n",
    "    )\n",
    "  return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TOP_P: 0.01, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and analyzing machine '\n",
      " 'learning experiments. It provides powerful visualizations and insights into '\n",
      " 'model performance, enabling data scientists to quickly identify areas of '\n",
      " 'improvement and optimize their models.')\n",
      "('TOP_P: 0.1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an amazing tool for tracking and analyzing machine '\n",
      " 'learning experiments. It provides powerful visualizations and insights into '\n",
      " 'model performance, enabling data scientists to quickly identify areas of '\n",
      " 'improvement and optimize their models.')\n",
      "('TOP_P: 0.5, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is an incredibly powerful tool for tracking and visualizing '\n",
      " 'machine learning experiments. It allows users to quickly and easily compare '\n",
      " 'different models and track their performance over time, helping them make '\n",
      " 'better decisions about which models to use and how')\n",
      "('TOP_P: 1, GENERATION: \\n'\n",
      " '\\n'\n",
      " 'Weights & Biases is a great tool for helping machine learning and deep '\n",
      " 'learning practitioners improve their models faster and easier. It provides '\n",
      " 'an extensive set of features for tracking, sharing, and analysing '\n",
      " 'experiments so that users can quickly compare and optim')\n"
     ]
    }
   ],
   "source": [
    "for topp in [0.01, 0.1, 0.5, 1]:\n",
    "  pprint(f'TOP_P: {topp}, GENERATION: {generate_with_topp(topp)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat API\n",
    "Let's switch to chat mode and see how the model responds to our messages. We have some control over the model's response by passing a system-role, here we can steer to model to adhere to a certain behaviour.\n",
    "> We are using gpt-3.5-turbo, this model is faster and cheaper than davinci-003 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-8DaY1AMBZjascQo8h91lUwEO4iTXV at 0x1789a7f1990> JSON: {\n",
       "  \"id\": \"chatcmpl-8DaY1AMBZjascQo8h91lUwEO4iTXV\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1698249445,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Weights & Biases is a powerful tool for machine learning experimentation and collaboration. It provides a platform to track and visualize experiments, making it easier to understand and iterate on models. With features like hyperparameter sweeps and experiment comparison, it helps researchers and data scientists optimize their models and make informed decisions. Additionally, Weights & Biases offers integrations with popular machine learning frameworks, making it seamless to incorporate into existing workflows.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 25,\n",
       "    \"completion_tokens\": 84,\n",
       "    \"total_tokens\": 109\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Say something about Weights & Biases\"},\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the response is a JSON object with relevant information about the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Weights & Biases is a powerful tool for machine learning experimentation and '\n",
      " 'collaboration. It provides a platform to track and visualize experiments, '\n",
      " 'making it easier to understand and iterate on models. With features like '\n",
      " 'hyperparameter sweeps and experiment comparison, it helps researchers and '\n",
      " 'data scientists optimize their models and make informed decisions. '\n",
      " 'Additionally, Weights & Biases offers integrations with popular machine '\n",
      " 'learning frameworks, making it seamless to incorporate into existing '\n",
      " 'workflows.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>ââââââââââ</td></tr><tr><td>usage/elapsed_time</td><td>ââââââââââ</td></tr><tr><td>usage/prompt_tokens</td><td>ââââââââââ</td></tr><tr><td>usage/total_tokens</td><td>ââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>usage/completion_tokens</td><td>84</td></tr><tr><td>usage/elapsed_time</td><td>0.0</td></tr><tr><td>usage/prompt_tokens</td><td>25</td></tr><tr><td>usage/total_tokens</td><td>109</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glamorous-meadow-1</strong> at: <a href='https://wandb.ai/arrogantemartin/llmapps/runs/7ru4abo3' target=\"_blank\">https://wandb.ai/arrogantemartin/llmapps/runs/7ru4abo3</a><br/>Synced 5 W&B file(s), 10 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231025_232009-7ru4abo3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "privateGpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
